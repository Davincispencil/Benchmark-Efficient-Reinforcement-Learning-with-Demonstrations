@article{sermanet2016unsupervised,
  title={Unsupervised perceptual rewards for imitation learning},
  author={Sermanet, Pierre and Xu, Kelvin and Levine, Sergey},
  journal={arXiv preprint arXiv:1612.06699},
  year={2016}
}


@inproceedings{hausman2017multi,
  title={Multi-modal imitation learning from unstructured demonstrations using generative adversarial nets},
  author={Hausman, Karol and Chebotar, Yevgen and Schaal, Stefan and Sukhatme, Gaurav and Lim, Joseph J},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1235--1245},
  year={2017}
}


@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}


@inproceedings{ammar2015autonomous,
  title={Autonomous cross-domain knowledge transfer in lifelong policy gradient reinforcement learning},
  author={Ammar, Haitham Bou and Eaton, Eric and Luna, Jos{\'e} Marcio and Ruvolo, Paul},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{ma2018universal,
  title={Universal successor representations for transfer reinforcement learning},
  author={Ma, Chen and Wen, Junfeng and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1804.03758},
  year={2018}
}


@inproceedings{machado2015domain,
  title={Domain-independent optimistic initialization for reinforcement learning},
  author={Machado, Marlos C and Srinivasan, Sriram and Bowling, Michael},
  booktitle={Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}


@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}


@inproceedings{brys2015reinforcement,
  title={Reinforcement learning from demonstration through shaping},
  author={Brys, Tim and Harutyunyan, Anna and Suay, Halit Bener and Chernova, Sonia and Taylor, Matthew E and Now{\'e}, Ann},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{gao2018reinforcement,
  title={Reinforcement learning from imperfect demonstrations},
  author={Gao, Yang and Lin, Ji and Yu, Fisher and Levine, Sergey and Darrell, Trevor and others},
  journal={arXiv preprint arXiv:1802.05313},
  year={2018}
}


@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}


@article{de2005tutorial,
  title={A tutorial on the cross-entropy method},
  author={De Boer, Pieter-Tjerk and Kroese, Dirk P and Mannor, Shie and Rubinstein, Reuven Y},
  journal={Annals of operations research},
  volume={134},
  number={1},
  pages={19--67},
  year={2005},
  publisher={Springer}
}


@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}


@inproceedings{van2007reinforcement,
  title={Reinforcement learning in continuous action spaces},
  author={Van Hasselt, Hado and Wiering, Marco A},
  booktitle={2007 IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning},
  pages={272--279},
  year={2007},
  organization={IEEE}
}


@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{arulkumaran2017brief,
  title={A brief survey of deep reinforcement learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}


@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}


@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}


@inproceedings{russell1998learning,
  title={Learning agents for uncertain environments},
  author={Russell, Stuart J},
  booktitle={COLT},
  volume={98},
  pages={101--103},
  year={1998}
}


@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4565--4573},
  year={2016}
}


@article{heess2017emergence,
  title={Emergence of locomotion behaviours in rich environments},
  author={Heess, Nicolas and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, SM and Riedmiller, Martin and others},
  journal={arXiv preprint arXiv:1707.02286},
  year={2017}
}


@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5048--5058},
  year={2017}
}


@article{ravi2016optimization,
  title={Optimization as a model for few-shot learning},
  author={Ravi, Sachin and Larochelle, Hugo},
  year={2016}
}


@inproceedings{andrychowicz2016learning,
  title={Learning to learn by gradient descent by gradient descent},
  author={Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3981--3989},
  year={2016}
}


@article{mishra2017simple,
  title={A simple neural attentive meta-learner},
  author={Mishra, Nikhil and Rohaninejad, Mostafa and Chen, Xi and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1707.03141},
  year={2017}
}


@article{yu2018one,
  title={One-shot imitation from observing humans via domain-adaptive meta-learning},
  author={Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.01557},
  year={2018}
}


@inproceedings{finn2018probabilistic,
  title={Probabilistic model-agnostic meta-learning},
  author={Finn, Chelsea and Xu, Kelvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9516--9527},
  year={2018}
}


@article{antoniou2018train,
  title={How to train your MAML},
  author={Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
  journal={arXiv preprint arXiv:1810.09502},
  year={2018}
}


@article{deleu2018effects,
  title={The effects of negative adaptation in Model-Agnostic Meta-Learning},
  author={Deleu, Tristan and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1812.02159},
  year={2018}
}


@inproceedings{chow2014algorithms,
  title={Algorithms for CVaR optimization in MDPs},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad},
  booktitle={Advances in neural information processing systems},
  pages={3509--3517},
  year={2014}
}


@article{finn2017one,
  title={One-shot visual imitation learning via meta-learning},
  author={Finn, Chelsea and Yu, Tianhe and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.04905},
  year={2017}
}


@inproceedings{duan2017one,
  title={One-shot imitation learning},
  author={Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Ho, OpenAI Jonathan and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  booktitle={Advances in neural information processing systems},
  pages={1087--1098},
  year={2017}
}


@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}


@inproceedings{koutnik2013evolving,
  title={Evolving large-scale neural networks for vision-based reinforcement learning},
  author={Koutn{\'\i}k, Jan and Cuccu, Giuseppe and Schmidhuber, J{\"u}rgen and Gomez, Faustino},
  booktitle={Proceedings of the 15th annual conference on Genetic and evolutionary computation},
  pages={1061--1068},
  year={2013},
  organization={ACM}
}


@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}


@inproceedings{molchanov2017variational,
  title={Variational dropout sparsifies deep neural networks},
  author={Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2498--2507},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{blau2018improving,
  title={Improving Reinforcement Learning Pre-Training with Variational Dropout},
  author={Blau, Tom and Ott, Lionel and Ramos, Fabio},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4115--4122},
  year={2018},
  organization={IEEE}
}


@inproceedings{pastor2009learning,
  title={Learning and generalization of motor skills by learning from demonstration},
  author={Pastor, Peter and Hoffmann, Heiko and Asfour, Tamim and Schaal, Stefan},
  booktitle={2009 IEEE International Conference on Robotics and Automation},
  pages={763--768},
  year={2009},
  organization={IEEE}
}


@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}


@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}


@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}


@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@inproceedings{schulman2015trust,
  title={Trust Region Policy Optimization.},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael I and Moritz, Philipp},
  booktitle={Icml},
  volume={37},
  pages={1889--1897},
  year={2015}
}


@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={ICML},
  year={2014}
}


@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}


@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}


@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}


@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}


@article{wang2016learning,
  title={Learning to reinforcement learn},
  author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  journal={arXiv preprint arXiv:1611.05763},
  year={2016}
}


@article{duan2016rl,
  title={RL $\^{} 2$: Fast Reinforcement Learning via Slow Reinforcement Learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}


@article{vuorio2018toward,
  title={Toward Multimodal Model-Agnostic Meta-Learning},
  author={Vuorio, Risto and Sun, Shao-Hua and Hu, Hexiang and Lim, Joseph J},
  journal={arXiv preprint arXiv:1812.07172},
  year={2018}
}

@article{vuorio2018toward,
  title={Toward Multimodal Model-Agnostic Meta-Learning},
  author={Vuorio, Risto and Sun, Shao-Hua and Hu, Hexiang and Lim, Joseph J},
  journal={arXiv preprint arXiv:1812.07172},
  year={2018}
}

@article{stadie2018some,
  title={Some considerations on learning to explore via meta-reinforcement learning},
  author={Stadie, Bradly C and Yang, Ge and Houthooft, Rein and Chen, Xi and Duan, Yan and Wu, Yuhuai and Abbeel, Pieter and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1803.01118},
  year={2018}
}


@article{duan2016rl,
  title={RL $\^{} 2$: Fast Reinforcement Learning via Slow Reinforcement Learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}


@article{nichol2018first,
  title={On first-order meta-learning algorithms},
  author={Nichol, Alex and Achiam, Joshua and Schulman, John},
  journal={CoRR, abs/1803.02999},
  volume={2},
  year={2018}
}


@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1126--1135},
  year={2017},
  organization={JMLR. org}
}


@article{vevcerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Ve{\v{c}}er{\'\i}k, Matej and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}


@article{johannink2018residual,
	title={Residual reinforcement learning for robot control},
	author={Johannink, Tobias and Bahl, Shikhar and Nair, Ashvin and Luo, Jianlan and Kumar, Avinash and Loskyll, Matthias and Ojea, Juan Aparicio and Solowjow, Eugen and Levine, Sergey},
	journal={arXiv preprint arXiv:1812.03201},
	year={2018}
}


@article{article,
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
year = {2014},
month = {06},
pages = {},
title = {Deterministic Policy Gradient Algorithms},
volume = {1},
journal = {31st International Conference on Machine Learning, ICML 2014}
}

@article{DBLP:journals/corr/LillicrapHPHETS15,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/1509.02971},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.02971},
  archivePrefix = {arXiv},
  eprint    = {1509.02971},
  timestamp = {Mon, 13 Aug 2018 16:46:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LillicrapHPHETS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}




@article{einstein,
  author =       "Albert Einstein",
  title =        "{Zur Elektrodynamik bewegter K{\"o}rper}. ({German})
                 [{On} the electrodynamics of moving bodies]",
  journal =      "Annalen der Physik",
  volume =       "322",
  number =       "10",
  pages =        "891--921",
  year =         "1905",
  DOI =          "http://dx.doi.org/10.1002/andp.19053221004"
}